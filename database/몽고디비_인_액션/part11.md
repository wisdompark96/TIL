### 복제의 사용 예와 한계
복제는 일차적으로 중복성을 위해 설계된다. 중복성으로 인해 복제 노드는 프라이머리 노드와 동기화된 상태를 유지한다. 이 복제 노드는 프라이머리 노드가 존재하는 같은 데이터 센터에 놓여 있거나 아니면 추가적인 안전 장치로서 지리적으로 분산될 수도 있다. 복제는 비동기적이므로 노드 사이의 어떠한 종류의 네트워크 지연이나 장애도 프라이머리 노드의 성능에 영향을 끼치지 못한다. 중복성의 또 다른 형태로서 복제 노드는 프라이머리보다 몇 초, 몇 분 심지어 몇 시간 정도 지연될 수  있다. 이것은 누군가 우발적으로 컬렉션을 삭제하거나 데이터베이스를 손상시키는 경우의 대비책이 된다.

정상적인 경우에는 이 삭제 연산이 바로 복제 노드에 적용되지만, 복제 도느에 대한 지연으로 인해 관리자는 조치를 취할 수 있는 시간을 갖게 된다.

복제의 또 다른 용례는 장애복구다. MongoDB의 복제 세트는 중복 노드를 가지고 있고 비상시에 이 중복 노드로 전환할 수 있는 능력이 있다.

중복가 장애복구 외에도 복제는 리소스를 많이 사용하는 연산을 프라이머리 외의 다른 노드에서 실행함으로써 데이터베이스 관리 작업을 단순하게 해준다.
예를 들면, 프라이머리 노드에서 필요없는 작업을 피하고 다운타임을 미연에 방지하기 위해 백업을 세컨더리 노드에서 수행하는 것이 일반적인 관행이다. 또 다른 예러는 대용량의 인덱스를 구축하는 것을 들 수 있다. 인덱스 구축은 리소스가 많이 필요하므로 세컨더리 노드에 대해 먼저 구축한 후에 기존의 프라이머리와 세컨더리 노드를 서로 바꾸고, 새로 세컨더리 노드가 된 이전의 프라이머리 노드에 대해 인덱스를 구축한다.

복제는 복제 노드 간 로드 밸런스를 해준다.  

복제 세트는 다음과 같은 조건에서는 별로 도움이 되지 않는다.
- 할당된 하드웨어가 주어진 일을 처리할 수 없을 때. 쓰기가 동시에 발생하고 그 수의 일부를 소비하는 경우에는 특히 그렇다. 이 경우 샤딩(sharding)이 더 나은 옵션이 될 수 있다.
- 읽기에 대한 쓰기의 비율이 50%를 초과하는 경우. 여기서 문제는 프라이머리에 대한 모든 쓰기 연산이 결국 세컨더리 노드에도 적용되어야 한다는 조ㅓㅁ이다. 따라서 이미 쓰기 연산을 활발하게 수행중인 세컨더리 노드에 읽기 요청을 하는 것은 복제 프로세스도 지연시키고 읽기 효율도 향상되지 못할 수 있다.
- 애플리케이션에서 일관성이 요구되는 읽기가 필요한 때. 세컨더리 노드는 비동기적으로 복제를 수행하므로 프라이머리 노드에서 수행된 마지막 쓰기를 반영하지 못할 수도 있다.

복제 세트는 즉각적인 일관성이 필요하지 않은 읽기 확장에 적합하지만, 그렇다고 모든 상황에서 도움이 되는 것은 아니다. 위와 같은 조건 중 어느 하나에 해당하는 상황에서 확장을 하려면 샤딩이나 하드웨어 업그레이드 혹은 이 둘을 모두 적용하는 것과 같은 다른 전략이 필요하다.

## 복제 세트
### 셋업
복제 세트에 대해 권장되는 최소의 구성은 세 개의 노드로 이뤄진 것인데, 이는 노드가 두 개인 복제 세트에서 프라이머리 서버가 다운될 경우 과반수를 확보할 수 없기 때문이다. 3-멤버 복제 세트에는 데이터를 보유하는 세 맴버 또는 데이터를 보유한 두 멤버와 아비터를 보유한 하나의 멤버가 있을 수 있다. 프라이머리는 복제 세트에서 쓰기 작업을 허용할 수 있는 유일한 멤버다.

복제 세트 멤버는 투표를 통해 새로운 마스터를 선출하는 프로세스를 거친다. 프라이머리가 사용할 수 없는 상태가 되면 선거로 인해 수동적인 개입 없이 정상적인 연산을 복구할 수 있다. 

복제 세트의 과반수가 액세스할 수 없거나 사용할 수 없는 경우 복제 세트는 쓰기를 허용할 수 없으며, 나머지 모든 멤버는 읽기 전용(read-only) 상태로 전환된다. 상호간의 네트워크 파티션이 가능한 두 위치에 동일한 수의 노드가 있는 경우 복제 세트에 아비터를 추가하는 것을 고려할 수 있다. 그러한 경우 아비터는 두 시설 간의 동점 관계를 깨고 복제 세트가 새로운 프라이머리를 선출하도록 할 것이다.

아비터는 프라이머리 선출에 참여하지만, 그 어떤 데이터도 복제하지 않는 경량의 mongod서버다.

### 복재 작동 방식
복제 세트는 오피로그(oplog)와 하트비트(heartbeat)라는 두 가지 기본적인 메커니즘에 의존한다. 오피로그를 통해 데이터 복제가 가능하고, 하트비트를 통해 시스템의 건강 상태를 모니터링함으로써 장애복구를 할 수 있다.

**오피로그**  
MongoDB 복제의 중심에는 오피로그가 있다. 오피로그는 캡드(capped) 컬렉션으로 모든 복제 노드에서 local이라는 데이터베이스 내에 있고, 데이터에 대한 모든 수정사항을 기록한다. 클라이언트가 프라이머리 노드에 대해 쓰기를 할 때마다 해당 쓰기를 세컨더리에서 재생하기 위한 충분한 정보가 프라이머리 노드의 오피로그에 자동으로 추가된다. 일단 쓰기가 세컨더리 노드에 복제되고 나면 쓰기 정보가 그 세컨더리 노드의 오피로그에도 기록된다.

각 오피로그 항목은 BSON 타임스탬프로 인식하고, 모든 세컨더리는 그 타임스탬프를 이용해서 적용할 최신 항목을 추적한다.
